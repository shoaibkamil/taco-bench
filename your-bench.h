#include "taco/tensor.h"

using namespace taco;
using namespace std;
#define restrict __restrict__

// Generated by the Tensor Algebra Compiler (tensor-compiler.org)
// taco "C(i,j)=A(i,k)*B(k,j)" -f=C:dd:0,1 -f=A:ds:0,1 -f=B:dd:1,0 -write-source=taco_kernel.c -write-compute=taco_compute.c -write-assembly=taco_assembly.c
#ifndef TACO_C_HEADERS
#define TACO_C_HEADERS
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>
#define TACO_MIN(_a,_b) ((_a) < (_b) ? (_a) : (_b))
#ifndef TACO_TENSOR_T_DEFINED
#define TACO_TENSOR_T_DEFINED
typedef enum { taco_dim_dense, taco_dim_sparse } taco_dim_t;
typedef struct {
    int32_t     order;      // tensor order (number of dimensions)
    int32_t*    dims;       // tensor dimensions
    taco_dim_t* dim_types;  // dimension storage types
    int32_t     csize;      // component size
    int32_t*    dim_order;  // dimension storage order
    uint8_t***  indices;    // tensor index data (per dimension)
    uint8_t*    vals;       // tensor values
} taco_tensor_t;
#endif
#endif

int assemble(taco_tensor_t *C, taco_tensor_t *A, taco_tensor_t *B) {
    int C1_size = *(int*)(C->indices[0][0]);
    int C2_size = *(int*)(C->indices[1][0]);
    double* restrict C_vals = (double*)(C->vals);
    
    C_vals = (double*)malloc(sizeof(double) * (C1_size * C2_size));
    
    C->vals = (uint8_t*)C_vals;
    return 0;
}

int compute(taco_tensor_t *C, taco_tensor_t *A, taco_tensor_t *B) {
    int C1_size = *(int*)(C->indices[0][0]);
    int C2_size = *(int*)(C->indices[1][0]);
    double* restrict C_vals = (double*)(C->vals);
    int A1_size = *(int*)(A->indices[0][0]);
    int* restrict A2_pos = (int*)(A->indices[1][0]);
    int* restrict A2_idx = (int*)(A->indices[1][1]);
    double* restrict A_vals = (double*)(A->vals);
    int B1_size = *(int*)(B->indices[0][0]);
    int B2_size = *(int*)(B->indices[1][0]);
    double* restrict B_vals = (double*)(B->vals);
    
#pragma omp parallel for
    for (int32_t iA = 0; iA < A1_size; iA++) {
        for (int32_t jB = 0; jB < B1_size; jB++) {
            int32_t pC2 = (iA * C2_size) + jB;
            double tk = 0;
            for (int32_t pA2 = A2_pos[iA]; pA2 < A2_pos[iA + 1]; pA2++) {
                int32_t kA = A2_idx[pA2];
                int32_t pB2 = (jB * B2_size) + kA;
                tk += A_vals[pA2] * B_vals[pB2];
            }
            C_vals[pC2] = tk;
        }
    }
    
    return 0;
}

void buildTensorT(Tensor<double> tensor, taco_tensor_t* tensorData) {
    size_t order = tensor.getOrder();
    auto storage = tensor.getStorage();
    auto format = storage.getFormat();
    
    tensorData->order     = order;
    tensorData->dims      = (int32_t*)malloc(order * sizeof(int32_t));
    tensorData->dim_types = (taco_dim_t*)malloc(order * sizeof(taco_dim_t));
    tensorData->dim_order = (int32_t*)malloc(order * sizeof(int32_t));
    tensorData->indices   = (uint8_t***)malloc(order * sizeof(uint8_t***));
    
    auto index = storage.getIndex();
    for (size_t i = 0; i < tensor.getOrder(); i++) {
        auto dimType  = format.getModeTypes()[i];
        auto dimIndex = index.getModeIndex(i);
        
        tensorData->dims[i] = tensor.getDimension(i);
        tensorData->dim_order[i] = format.getModeOrder()[i];
        
        switch (dimType) {
            case ModeType::Dense: {
                tensorData->dim_types[i]  = taco_dim_dense;
                tensorData->indices[i]    = (uint8_t**)malloc(1 * sizeof(uint8_t**));
                
                auto size = dimIndex.getIndexArray(0);
                tensorData->indices[i][0] = (uint8_t*)size.getData();
                break;
            }
            case ModeType::Sparse: {
                tensorData->dim_types[i]  = taco_dim_sparse;
                tensorData->indices[i]    = (uint8_t**)malloc(2 * sizeof(uint8_t**));
                
                // When packing results for assemblies they won't have sparse indices
                if (dimIndex.numIndexArrays() == 0) {
                    continue;
                }
                
                auto pos = dimIndex.getIndexArray(0);
                auto idx = dimIndex.getIndexArray(1);
                tensorData->indices[i][0] = (uint8_t*)pos.getData();
                tensorData->indices[i][1] = (uint8_t*)idx.getData();
            }
                break;
            case ModeType::Fixed:
                taco_not_supported_yet;
                break;
        }
    }
    
    tensorData->csize = tensor.getComponentType().getNumBits();
    tensorData->vals  = (uint8_t*)storage.getValues().getData();
    //tensorData->vals = nullptr;
    
}

#ifdef YOUR
// Add your include here
// ...

  void exprToYOURS(BenchExpr Expr, map<string,Tensor<double>> exprOperands,int repeat, taco::util::TimeResults timevalue) {
    switch(Expr) {
      case SparsitySpMDM: {
//        int rows=exprOperands.at("CRef").getDimension(0);
//        int cols=exprOperands.at("CRef").getDimension(1);
//        Tensor<double> B({cols, rows}, Format({Dense,Dense}));
//        util::fillMatrix(B,util::FillMethod::Dense,1.0);
//        Tensor<double> CRef({rows, cols}, Format({Dense,Dense}));
//        Tensor<double> A({rows,cols}, Format({Dense,Dense}));
//        util::fillMatrix(A,util::FillMethod::Dense,1.0);
//
//        IndexVar i, j, k;
//        CRef(i, j) = A(i, k) * B(k, j);
//        CRef.compile();
//        CRef.assemble();
//        TACO_BENCH(CRef.compute();, "Compute",repeat, timevalue, true)
//
//        break;
          taco_tensor_t A, B, C;
          int rows=exprOperands.at("CRef").getDimension(0);
          int cols=exprOperands.at("CRef").getDimension(1);
          Tensor<double> tensorC({rows,cols}, Format({Dense,Dense}));
          
          buildTensorT(tensorC, &C);
          buildTensorT(exprOperands.at("A"), &A);
          buildTensorT(exprOperands.at("B"), &B);
          
          assemble(&C, &A, &B);

          TACO_BENCH(compute(&C, &A, &B), "Customized compute", repeat, timevalue, true);
//          validate("custom", tensorC, exprOperands.at("CRef"));
          for (int i=0; i<rows; i++)
              for (int j=0; j<cols; j++) {
                  auto val = *((double*)C.vals+i+j*rows);
                  auto ref = *((double*)(exprOperands.at("CRef").getStorage().getValues().getData())+i+j*rows);
                  if (fabs(ref-val) > 1e-10) {
                      std::cerr << "Validation error at " << i << "," << j << endl;
                      return;
                  }
              }
          break;
      }

      case SpMV:
        // Add code for your implementation of SpMV
        // ..
        // Use TACO_BENCH macro to benchmark your implementation
        // ..
        // Use validate method to compare against expected results
        // ..
      case PLUS3:
      case MATTRANSMUL:
      case RESIDUAL:
      case SDDMM:
      
      default:
        cout << " !! Expression not implemented for your" << endl;
        break;
    }
  }

#endif
